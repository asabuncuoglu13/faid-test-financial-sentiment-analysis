{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tested in transformers==4.18.0 \n",
    "from transformers import BertTokenizer,BertForSequenceClassification, BertConfig, pipeline, utils\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asabuncuoglu/Documents/faid-test-financial-sentiment-analysis/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3, output_attentions=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "config = BertConfig.from_pretrained('yiyanghkust/finbert-tone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", model=finbert, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folders = [\n",
    "    \"../../data/output/synth-findata/mistral-large/gn_negative_tone_positive_phrase\",\n",
    "    \"../../data/output/synth-findata/mistral-large/gs_negative_tone_positive_phrase\",\n",
    "    \"../../data/output/synth-findata/mistral-large/gn_positive_tone_positive_phrase\",\n",
    "    \"../../data/output/synth-findata/mistral-large/gs_positive_tone_positive_phrase\",\n",
    "]\n",
    "\n",
    "for input_folder in input_folders:\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            pred = pipe(df['response'].to_list())\n",
    "\n",
    "            df['label'] = [p['label'] for p in pred]\n",
    "            df['score'] = [p['score'] for p in pred]\n",
    "            df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'y_true': [], 'y_pred': [], 'country': [], 'pos': []}\n",
    "gsdf = pd.DataFrame(data)\n",
    "\n",
    "gs_folders = [\n",
    "    \"../../data/output/synth-findata/mistral-large/gs_negative_tone_positive_phrase\",\n",
    "    \"../../data/output/synth-findata/mistral-large/gs_positive_tone_positive_phrase\",\n",
    "]\n",
    "\n",
    "out_file = \"../../data/output/synth-findata/mistral-large/gs_predictions.csv\"\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "country = []\n",
    "\n",
    "for input_folder in gs_folders:\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            y_true.extend(df[\"sentiment\"].to_list())\n",
    "            y_pred.extend(df[\"label\"].str.lower().to_list())\n",
    "            country.extend(df[\"country\"].to_list())\n",
    "\n",
    "gsdf[\"y_true\"] = y_true\n",
    "gsdf[\"y_pred\"] = y_pred\n",
    "gsdf[\"country\"] = country\n",
    "gsdf[\"pos\"] = [\"GS\"] * len(gsdf)\n",
    "\n",
    "gsdf.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'y_true': [], 'y_pred': [], 'country': [], 'pos': []}\n",
    "gndf = pd.DataFrame(data)\n",
    "\n",
    "gn_folders = [\n",
    "    \"../../data/output/synth-findata/mistral-large/gn_negative_tone_positive_phrase\",\n",
    "    \"../../data/output/synth-findata/mistral-large/gn_positive_tone_positive_phrase\",\n",
    "]\n",
    "\n",
    "out_file = \"../../data/output/synth-findata/mistral-large/gn_predictions.csv\"\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "country = []\n",
    "\n",
    "for input_folder in gn_folders:\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            y_true.extend(df[\"sentiment\"].to_list())\n",
    "            y_pred.extend(df[\"label\"].str.lower().to_list())\n",
    "            country.extend(df[\"country\"].to_list())\n",
    "\n",
    "gndf[\"y_true\"] = y_true\n",
    "gndf[\"y_pred\"] = y_pred\n",
    "gndf[\"country\"] = country\n",
    "gndf[\"pos\"] = [\"GN\"] * len(gndf)\n",
    "\n",
    "gndf.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"../../data/output/synth-findata/mistral-large/all_predictions.csv\"\n",
    "merged_df = pd.concat([gndf, gsdf])\n",
    "merged_df.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = merged_df[\"y_true\"].map({\"positive\": 1, \"negative\": 0})\n",
    "y_pred = merged_df[\"y_pred\"].map({\"positive\": 1, \"negative\": 0})\n",
    "sf_data = merged_df[\"pos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_locations = y_pred[y_pred.isna()].index\n",
    "y_pred = y_pred.drop(nan_locations)\n",
    "y_true = y_true.drop(nan_locations)\n",
    "sf_data = sf_data.drop(nan_locations)\n",
    "\n",
    "nan_locations = y_true[y_true.isna()].index\n",
    "y_pred = y_pred.drop(nan_locations)\n",
    "y_true = y_true.drop(nan_locations)\n",
    "sf_data = sf_data.drop(nan_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import MetricFrame\n",
    "from fairlearn.metrics import count, \\\n",
    "                              false_positive_rate, \\\n",
    "                              selection_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Define a custom recall function with average='macro' and pos_label='positive'\n",
    "def recall_macro(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Construct a function dictionary\n",
    "my_metrics = {\n",
    "    'tpr' : recall_macro,\n",
    "    'fpr' : false_positive_rate,\n",
    "    'sel' : selection_rate,\n",
    "    'count' : count\n",
    "}\n",
    "\n",
    "# Construct a MetricFrame\n",
    "mf = MetricFrame(\n",
    "    metrics=my_metrics,\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=sf_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tpr          0.987420\n",
       "fpr          0.024713\n",
       "sel          0.508557\n",
       "count    13497.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>sel</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GN</th>\n",
       "      <td>0.980725</td>\n",
       "      <td>0.038247</td>\n",
       "      <td>0.511867</td>\n",
       "      <td>6699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS</th>\n",
       "      <td>0.994116</td>\n",
       "      <td>0.011180</td>\n",
       "      <td>0.505296</td>\n",
       "      <td>6798.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tpr       fpr       sel   count\n",
       "pos                                      \n",
       "GN   0.980725  0.038247  0.511867  6699.0\n",
       "GS   0.994116  0.011180  0.505296  6798.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tpr      0.980725\n",
       "fpr       0.01118\n",
       "sel      0.505296\n",
       "count      6699.0\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.group_min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tpr      0.994116\n",
       "fpr      0.038247\n",
       "sel      0.511867\n",
       "count      6798.0\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.group_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tpr       0.013391\n",
       "fpr       0.027067\n",
       "sel       0.006572\n",
       "count    99.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.difference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tpr      0.986530\n",
       "fpr      0.292308\n",
       "sel      0.987161\n",
       "count    0.985437\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tpr         0.006696\n",
       "fpr         0.013533\n",
       "sel         0.003310\n",
       "count    6798.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.difference(method='to_overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tpr      0.993220\n",
       "fpr      0.452381\n",
       "sel      0.993534\n",
       "count    0.496333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.ratio(method='to_overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9871611922296122\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import demographic_parity_ratio\n",
    "print(demographic_parity_ratio(y_true,\n",
    "                               y_pred,\n",
    "                               sensitive_features=sf_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2923076923076924\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import equalized_odds_ratio\n",
    "print(equalized_odds_ratio(y_true,\n",
    "                               y_pred,\n",
    "                               sensitive_features=sf_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2923076923076924"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(mf.ratio(method=\"between_groups\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
