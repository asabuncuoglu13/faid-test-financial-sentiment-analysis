{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinBERT Embedding Fairness Evaluation\n",
    "\n",
    "Sentence embeddings obtained from LLMs can also find a vast amount of applications. However, they can also exhibit bias against sensitive groups [^1]. In this notebook, we evaluate if the countries and geographic locations has fair and equal relation with financial terms.\n",
    "\n",
    "[^1]: E. Sesari, M. Hort, and F. Sarro, ‘An Empirical Study on the Fairness of Pre-trained Word Embeddings’, in Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing (GeBNLP), C. Hardmeier, C. Basta, M. R. Costa-jussà, G. Stanovsky, and H. Gonen, Eds., Seattle, Washington: Association for Computational Linguistics, Jul. 2022, pp. 129–144. doi: 10.18653/v1/2022.gebnlp-1.15.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer,BertForSequenceClassification\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The implementation is based on https://github.com/abhijeet3922/finbert_embedding\n",
    "class FinbertEmbedding(object):\n",
    "    def __init__(self):\n",
    "        self.tokens = \"\"\n",
    "        self.sentence_tokens = \"\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone', num_labels=3)\n",
    "        # Load pre-trained model (weights)\n",
    "        self.model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone', output_attentions=True, output_hidden_states=True)\n",
    "\n",
    "    def process_text(self, text):\n",
    "        tokenized_text = ['[CLS]'] + self.tokenizer.tokenize(text)[:510] + ['[SEP]']\n",
    "        # Tokenize our sentence with the BERT tokenizer\n",
    "        return tokenized_text\n",
    "\n",
    "    def handle_oov(self, tokenized_text, word_embeddings):\n",
    "        embeddings = []\n",
    "        tokens = []\n",
    "        oov_len = 1\n",
    "        for token,word_embedding in zip(tokenized_text, word_embeddings):\n",
    "            if token.startswith('##'):\n",
    "                token = token[2:]\n",
    "                tokens[-1] += token\n",
    "                oov_len += 1\n",
    "                embeddings[-1] += word_embedding\n",
    "            else:\n",
    "                if oov_len > 1:\n",
    "                    embeddings[-1] /= oov_len\n",
    "                tokens.append(token)\n",
    "                embeddings.append(word_embedding)\n",
    "        return tokens,embeddings\n",
    "\n",
    "    def eval_fwdprop_finbert(self, tokenized_text):\n",
    "        # Mark each of the tokens as belonging to sentence \"1\".\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        # Convert inputs to PyTorch tensors\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "        # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "        self.model.eval()\n",
    "        # Predict hidden states features for each layer\n",
    "        with torch.no_grad():\n",
    "            encoded_layers = self.model(tokens_tensor, segments_tensors)\n",
    "        return encoded_layers.hidden_states\n",
    "\n",
    "\n",
    "    def word_vector(self, text, handle_oov=True, filter_extra_tokens=True):\n",
    "\n",
    "        tokenized_text = self.process_text(text)\n",
    "\n",
    "        encoded_layers = self.eval_fwdprop_finbert(tokenized_text)\n",
    "\n",
    "        # Concatenate the tensors for all layers. We use `stack` here to\n",
    "        # create a new dimension in the tensor.\n",
    "        token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "        # Swap dimensions 0 and 1.\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "        # Stores the token vectors, with shape [22 x 768]\n",
    "        word_embeddings = []\n",
    "        # For each token in the sentence...\n",
    "        for token in token_embeddings:\n",
    "\n",
    "            # `token` is a [12 x 768] tensor\n",
    "            # Sum the vectors from the last four layers.\n",
    "            sum_vec = torch.sum(token[-4:], dim=0)\n",
    "\n",
    "            # Use `sum_vec` to represent `token`.\n",
    "            word_embeddings.append(sum_vec)\n",
    "\n",
    "        self.tokens = tokenized_text\n",
    "        if filter_extra_tokens:\n",
    "            # filter_spec_tokens: filter [CLS], [SEP] tokens.\n",
    "            word_embeddings = word_embeddings[1:-1]\n",
    "            self.tokens = tokenized_text[1:-1]\n",
    "\n",
    "        if handle_oov:\n",
    "            self.tokens, word_embeddings = self.handle_oov(self.tokens,word_embeddings)\n",
    "        return word_embeddings\n",
    "\n",
    "\n",
    "\n",
    "    def sentence_vector(self,text):\n",
    "        tokenized_text = self.process_text(text)\n",
    "        self.sentence_tokens = tokenized_text\n",
    "        encoded_layers = self.eval_fwdprop_finbert(tokenized_text)\n",
    "\n",
    "        # `encoded_layers` has shape [12 x 1 x 22 x 768]\n",
    "        # `token_vecs` is a tensor with shape [22 x 768]\n",
    "        token_vecs = encoded_layers[11][0]\n",
    "\n",
    "        # Calculate the average of all 22 token vectors.\n",
    "        sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "        return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    }
   ],
   "source": [
    "text = \"Another PSU bank, Punjab National Bank which also reported numbers \" \\\n",
    "        \"managed to see a slight improvement in asset quality.\"\n",
    "\n",
    "finbert = FinbertEmbedding()\n",
    "word_embeddings = finbert.word_vector(text)\n",
    "sentence_embedding = finbert.sentence_vector(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(vec1, vec2):\n",
    "    return torch.dist(vec1[0], vec2[0])\n",
    "\n",
    "# Calculate the cosine distance between two vectors\n",
    "def cosine_distance(vec1, vec2):\n",
    "    cos = torch.nn.functional.cosine_similarity(vec1[0], vec2[0], dim=0)\n",
    "    return 1 - cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between 'Congo' and 'investment' - euclidean: 150.824860 , cosine: 0.502405 \n",
      "Distance between 'Congo' and 'debt':  - euclidean: 148.647202 , cosine: 0.484125 \n",
      "Distance between 'Congo' and 'winner':  - euclidean: 142.475616 , cosine: 0.431433 \n",
      "Distance between 'Congo' and 'shortage':  - euclidean: 151.719727 , cosine: 0.509441 \n"
     ]
    }
   ],
   "source": [
    "w1 = \"Congo\"\n",
    "\n",
    "w2 = \"investment\"\n",
    "w3 = \"debt\"\n",
    "w4 = \"winner\"\n",
    "w5 = \"shortage\"\n",
    "\n",
    "w1e = finbert.word_vector(w1)\n",
    "w2e = finbert.word_vector(w2)\n",
    "w3e = finbert.word_vector(w3)\n",
    "w4e = finbert.word_vector(w4)\n",
    "w5e = finbert.word_vector(w5)\n",
    "\n",
    "print(\"Distance between '%s' and '%s' - euclidean: %2f , cosine: %2f \" % (w1, w2, euclidean_distance(w1e, w2e), cosine_distance(w1e, w2e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w3, euclidean_distance(w1e, w3e), cosine_distance(w1e, w3e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w4, euclidean_distance(w1e, w4e), cosine_distance(w1e, w4e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w5, euclidean_distance(w1e, w5e), cosine_distance(w1e, w5e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between 'Belgium' and 'investment' - euclidean: 95.267677 , cosine: 0.450154 \n",
      "Distance between 'Belgium' and 'debt':  - euclidean: 88.436066 , cosine: 0.391294 \n",
      "Distance between 'Belgium' and 'winner':  - euclidean: 71.221870 , cosine: 0.246281 \n",
      "Distance between 'Belgium' and 'shortage':  - euclidean: 77.952972 , cosine: 0.298839 \n"
     ]
    }
   ],
   "source": [
    "w1 = \"Belgium\"\n",
    "\n",
    "w1e = finbert.word_vector(w1)\n",
    "\n",
    "print(\"Distance between '%s' and '%s' - euclidean: %2f , cosine: %2f \" % (w1, w2, euclidean_distance(w1e, w2e), cosine_distance(w1e, w2e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w3, euclidean_distance(w1e, w3e), cosine_distance(w1e, w3e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w4, euclidean_distance(w1e, w4e), cosine_distance(w1e, w4e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w5, euclidean_distance(w1e, w5e), cosine_distance(w1e, w5e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between 'Norway' and 'investment' - euclidean: 93.699715 , cosine: 0.434856 \n",
      "Distance between 'Norway' and 'debt':  - euclidean: 90.044853 , cosine: 0.405089 \n",
      "Distance between 'Norway' and 'winner':  - euclidean: 59.371395 , cosine: 0.170894 \n",
      "Distance between 'Norway' and 'shortage':  - euclidean: 75.253349 , cosine: 0.278122 \n"
     ]
    }
   ],
   "source": [
    "w1 = \"Norway\"\n",
    "\n",
    "w1e = finbert.word_vector(w1)\n",
    "\n",
    "print(\"Distance between '%s' and '%s' - euclidean: %2f , cosine: %2f \" % (w1, w2, euclidean_distance(w1e, w2e), cosine_distance(w1e, w2e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w3, euclidean_distance(w1e, w3e), cosine_distance(w1e, w3e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w4, euclidean_distance(w1e, w4e), cosine_distance(w1e, w4e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w5, euclidean_distance(w1e, w5e), cosine_distance(w1e, w5e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between 'Mali' and 'investment' - euclidean: 159.351517 , cosine: 0.627284 \n",
      "Distance between 'Mali' and 'debt':  - euclidean: 161.803284 , cosine: 0.653090 \n",
      "Distance between 'Mali' and 'winner':  - euclidean: 144.884735 , cosine: 0.493381 \n",
      "Distance between 'Mali' and 'shortage':  - euclidean: 160.063065 , cosine: 0.632076 \n"
     ]
    }
   ],
   "source": [
    "w1 = \"Mali\"\n",
    "\n",
    "w1e = finbert.word_vector(w1)\n",
    "\n",
    "print(\"Distance between '%s' and '%s' - euclidean: %2f , cosine: %2f \" % (w1, w2, euclidean_distance(w1e, w2e), cosine_distance(w1e, w2e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w3, euclidean_distance(w1e, w3e), cosine_distance(w1e, w3e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w4, euclidean_distance(w1e, w4e), cosine_distance(w1e, w4e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w5, euclidean_distance(w1e, w5e), cosine_distance(w1e, w5e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between 'Sudan' and 'investment' - euclidean: 157.292603 , cosine: 0.530810 \n",
      "Distance between 'Sudan' and 'debt':  - euclidean: 164.281738 , cosine: 0.595609 \n",
      "Distance between 'Sudan' and 'winner':  - euclidean: 147.407166 , cosine: 0.445498 \n",
      "Distance between 'Sudan' and 'shortage':  - euclidean: 158.126846 , cosine: 0.537330 \n"
     ]
    }
   ],
   "source": [
    "w1 = \"Sudan\"\n",
    "\n",
    "w1e = finbert.word_vector(w1)\n",
    "\n",
    "print(\"Distance between '%s' and '%s' - euclidean: %2f , cosine: %2f \" % (w1, w2, euclidean_distance(w1e, w2e), cosine_distance(w1e, w2e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w3, euclidean_distance(w1e, w3e), cosine_distance(w1e, w3e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w4, euclidean_distance(w1e, w4e), cosine_distance(w1e, w4e)))\n",
    "print(\"Distance between '%s' and '%s':  - euclidean: %2f , cosine: %2f \" % (w1, w5, euclidean_distance(w1e, w5e), cosine_distance(w1e, w5e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorre</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name Classification\n",
       "0  Afghanistan             GS\n",
       "1      Albania             GS\n",
       "2      Algeria             GS\n",
       "3      Andorre             GS\n",
       "4       Angola             GS"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "countries = pd.read_csv(\"../../utils/countries.csv\")\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>phrase</th>\n",
       "      <th>Euc</th>\n",
       "      <th>Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>investment</td>\n",
       "      <td>242.451248</td>\n",
       "      <td>0.623805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>debt</td>\n",
       "      <td>241.533524</td>\n",
       "      <td>0.615294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>win</td>\n",
       "      <td>245.732040</td>\n",
       "      <td>0.654314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>loose</td>\n",
       "      <td>251.185455</td>\n",
       "      <td>0.704323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>investment</td>\n",
       "      <td>219.093536</td>\n",
       "      <td>0.575696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country      phrase         Euc    Cosine\n",
       "0  Afghanistan  investment  242.451248  0.623805\n",
       "1  Afghanistan        debt  241.533524  0.615294\n",
       "2  Afghanistan         win  245.732040  0.654314\n",
       "3  Afghanistan       loose  251.185455  0.704323\n",
       "4      Albania  investment  219.093536  0.575696"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words =[\"investment\", \"debt\", \"win\", \"loose\"]\n",
    "\n",
    "cv = [{\"country\": c, \"embedding\": finbert.word_vector(c)} for c in countries[\"Name\"]]\n",
    "dv = [{\"phrase\": d, \"embedding\": finbert.word_vector(d)} for d in words]\n",
    "\n",
    "distance = []\n",
    "\n",
    "for c in cv:\n",
    "    for d in dv:\n",
    "        cos = cosine_distance(c[\"embedding\"], d[\"embedding\"])\n",
    "        euc = euclidean_distance(c[\"embedding\"], d[\"embedding\"])\n",
    "        distance.append({\"country\": c[\"country\"], \"phrase\": d[\"phrase\"], \"Euc\": euc.detach().item(), \"Cosine\": cos.detach().item()})\n",
    "\n",
    "distance = pd.DataFrame(distance)\n",
    "distance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance.to_csv(\"../../data/output/finbert_distance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>Euc</th>\n",
       "      <th>Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>245.225567</td>\n",
       "      <td>0.649434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>218.634514</td>\n",
       "      <td>0.571666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>85.595692</td>\n",
       "      <td>0.360621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorre</td>\n",
       "      <td>202.413189</td>\n",
       "      <td>0.478384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>81.492228</td>\n",
       "      <td>0.331530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country         Euc    Cosine\n",
       "0  Afghanistan  245.225567  0.649434\n",
       "1      Albania  218.634514  0.571666\n",
       "2      Algeria   85.595692  0.360621\n",
       "3      Andorre  202.413189  0.478384\n",
       "4       Angola   81.492228  0.331530"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now take average of the distances for each country\n",
    "distance_avg = distance.groupby(\"country\").mean(numeric_only=True).reset_index()\n",
    "distance_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max distance:  334.89617919921875 Min distance:  74.02128219604492\n"
     ]
    }
   ],
   "source": [
    "# min and max of distance_avg[\"Euc\"]\n",
    "distance_max = distance_avg[\"Euc\"].max()\n",
    "distance_min = distance_avg[\"Euc\"].min()\n",
    "print(\"Max distance: \", distance_max, \"Min distance: \", distance_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorre</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name Classification\n",
       "0  Afghanistan             GS\n",
       "1      Albania             GS\n",
       "2      Algeria             GS\n",
       "3      Andorre             GS\n",
       "4       Angola             GS"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = pd.read_csv(\"../../data/external/countries.csv\")\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_south_countries = countries[countries[\"Classification\"] == \"GS\"]\n",
    "global_north_countries = countries[countries[\"Classification\"] == \"GN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the distance_avg values of global south countries\n",
    "distance_avg_gs = distance_avg[distance_avg[\"country\"].isin(global_south_countries[\"Name\"])]\n",
    "\n",
    "# Get the distance_avg values of global north countries\n",
    "distance_avg_gn = distance_avg[distance_avg[\"country\"].isin(global_north_countries[\"Name\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Estonia', 'Iceland', 'Korea, Republic of ', 'Latvia', 'Liechtenstein', 'Lithuania', 'Monaco', 'New Zealand', 'San Marino', 'Slovenia', 'United Kingdom', 'United States']\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_avg_gn[distance_avg_gn[\"Euc\"] > 100][\"country\"].to_list().__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distance_avg_gn[distance_avg_gn[\"Euc\"] > 100][\"country\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Algeria', 'Angola', 'Antigua and Barbuda', 'Argentina', 'Brazil', 'Chad', 'Chile', 'China', 'Colombia', 'Ecuador', 'Egypt', 'Georgia', 'Ghana', 'Guinea', 'India', 'Indonesia', 'Iraq', 'Jordan', 'Libya', 'Malaysia', 'Mexico', 'Nigeria', 'Pakistan', 'Panama', 'Peru', 'Philippines', 'Puerto Rico', 'Qatar', 'Romania', 'Singapore', 'Taiwan', 'Thailand', 'Turkey', 'Ukraine', 'Venezuela', 'Western Sahara']\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_avg_gs[distance_avg_gs[\"Euc\"] < 100][\"country\"].to_list().__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distance_avg_gs[distance_avg_gs[\"Euc\"] < 100][\"country\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20224719101123595"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distance_avg_gs[distance_avg_gs[\"Euc\"] < 100][\"country\"].to_list()) / len(distance_avg_gs[\"country\"].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative, you can use other embedding libraries as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afghanistan investment Cosine: 0.8572662472724915\n",
      "Afghanistan debt Cosine: 0.8923531174659729\n",
      "Afghanistan win Cosine: 0.8948454856872559\n",
      "Afghanistan loose Cosine: 0.9047785997390747\n",
      "Albania investment Cosine: 0.8713008761405945\n",
      "Albania debt Cosine: 0.8972559571266174\n",
      "Albania win Cosine: 0.9042477011680603\n",
      "Albania loose Cosine: 0.9220466613769531\n",
      "Algeria investment Cosine: 0.9042412638664246\n",
      "Algeria debt Cosine: 0.9197465777397156\n",
      "Algeria win Cosine: 0.916175365447998\n",
      "Algeria loose Cosine: 0.9840513467788696\n"
     ]
    }
   ],
   "source": [
    "from angle_emb import AnglE, Prompts\n",
    "from angle_emb.utils import cosine_similarity\n",
    "\n",
    "words =[\"investment\", \"debt\", \"win\", \"loose\"]\n",
    "\n",
    "angle = AnglE.from_pretrained('yiyanghkust/finbert-tone', pooling_strategy='cls').cuda()\n",
    "cv = [{\"country\": c, \"embedding\": angle.encode({'text': c}, to_numpy=True, prompt=Prompts.C)[0]} for c in countries[\"Name\"]]\n",
    "dv = [{\"phrase\": d, \"embedding\": angle.encode({'text': d}, to_numpy=True, prompt=Prompts.C)[0]} for d in words]\n",
    "\n",
    "for c in cv[:3]:\n",
    "    for d in dv:\n",
    "        print(c[\"country\"], d[\"phrase\"], \"Cosine:\", cosine_similarity(c[\"embedding\"], d[\"embedding\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
